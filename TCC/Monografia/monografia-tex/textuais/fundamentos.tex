%==============================================================================
\chapter{Fundamentos}\label{fundamentos}
%==============================================================================

Devido aos impasses demonstrados no \autoref{oproblema}, este trabalho é baseado em conceitos de aprendizado de máquina, que dedica-se na elaboraçãode algoritmos e técnicas que permitem um computador a aprender padrões.  

\section{Aprendizado de máquina}\label{sec:aprendizadodemaquina}

Para realizar a aprendizagem é necessário, a princípio, dados de entrada que servem como exemplo para nosso modelo, com esses dados é possível treinar o modelo para que ele possa então aprender com base nesses exemplos. Depois de realizar o treinamento, é possível generalizar sobre outros dados ainda não testados e gerar uma resposta apropriada como saída. O diagrama da \autoref{fig:passoapasso} abaixo mostra os passos para obter o resultado final.

\begin{figure}[htb]
	  \caption{Diagrama para resultado final}\label{fig:passoapasso}
	  \begin{center}
	      \includegraphics[scale=0.5]{img/passoapasso}
	  \end{center}
\end{figure}


O aprendizado de máquina pode ser dividido em duas abordagens: O \textbf{aprendizado supervisionado}, onde é dado um conjunto de dados de entrada e já se sabe como a saída deve parecer, tendo a ideia de que há uma relação entre a entrada e a saída; O \textbf{aprendizado não supervisionado}, que nos permite abordar problemas com pouca ou até nenhuma ideia de como os resultados devem parecer, nesse caso a caixa de exemplos de saída pode não existir.

Neste trabalho a abordagem utilizada vai ser o aprendizado supervisionado, pois já temos uma classe gramatical apropriada para cada palavra em seu contexto.

O aprendizado supervisionado permite dividir os problemas em duas categorias distintas:


\begin{itemize}
	\item \textbf{Regressão}: Tenta-se prever resultados com uma saída contínua, significando que deseja-se mapear variáveis de entrada em alguma função contínua. A \autoref{fig:demregressao} demonstra esse processo. Nessa demonstração, os círculos em vermelho são dados de exemplo, já a reta azul representa a predição feita pela regressão.
	\item \textbf{Classificação}:  Tenta-se prever resultados em uma saída discreta, ou seja, deseja0se mapear variáveis de entrada em categoriais discretas. A \autoref{fig:demclassificacao} demonstra esse processo. Essa demonstração tem duas classes diferentes, as representadas pelos círculos amarelos e pelas cruzes vermelhas, já o contorno em verde representa o resultado da classificação sobre esses dados de exemplo.
\end{itemize}


\begin{figure}[htb]
	  \caption{Demonstração de regressão}\label{fig:demregressao}
	  \begin{center}
	      \includegraphics[scale=0.75]{img/regressao2}
	  \end{center}
	  \legend{Fonte: \citeonline{machinelearningcoursera}}
\end{figure}

\begin{figure}[htb]
  \caption{Demonstração de classificação}\label{fig:demclassificacao}
  \begin{center}
      \includegraphics[scale=0.75]{img/classificacao2}
  \end{center}
  \legend{Fonte: \citeonline{machinelearningcoursera}}
\end{figure}


Logo adiante será explicado os fundamentos de classificação e uma técnica para resolver esse problema chamada de regressão logística \cite{hosmer2004applied}. E em virtude de apresentar conceitos fundamentais há serem aplicados posteriormente nas redes neurais profundas, será falado um pouco mais sobre regressão logística, e também sobre propriedades importantes que serão referenciadas durante todo o trabalho.

\subsection{Classificação}

Em um problema de classificação, nossa saída \textit{Y} vai ser um vetor com valores sendo apenas zero ou um.

\begin{equation}\label{eq:binaryclassification}
Y \in \{0, 1\}
\end{equation}

A equação \ref{eq:binaryclassification} está tratando apenas duas classes. Sendo assim, esse problema é chamado de classificação binária. Para resolver esse problema, um método que pode ser utilizado é regressão logística.

A fim de simplificar o uso das variáveis, faremos o uso de uma notação que é normalmente utilizada em textos de aprendizado de máquina, ela pode ser vista na \autoref{tab:classificacaonomenclatura}.

\begin{table}[!htb]
\caption{Nomenclaturas} \label{tab:classificacaonomenclatura}
\begin{center}
\begin{tabular}{m{2cm}m{14.0cm}}
  \toprule
  $X$ & dados de entrada ou \textit{features} \\
  $Y$ & dados de saída \\
  $X_j^{(i)}$ & o valor da \textit{feature} \textit{j} no i-ésimo exemplo de treinamento \\
  $X^{(i)}$ & o vetor coluna de todas as \textit{features} no i-ésimo exemplo de treinamento \\
  $m$ & número de exemplos de treinamento \\
  $n$ & $|X^{(i)}|$, o número de \textit{features} \\
  $(x, y)$ & um exemplo de treinamento \\
  $(X^{(i)}, Y^{(i)})$ & o i-ésimo exemplo de treinamento \\
  $\theta$ & parâmetros a serem aprendidos \\
  \bottomrule
\end{tabular}
\legend{Notação utilizada para classificação}
\end{center}

\end{table}



\ \\
\ \\

\subsection{Função de hipótese}

A função de hipótese descreve a confiança dos dados de entrada para os dados de saída, para isso é atribuido valores para os parâmetros $\theta$s. Essa relação está definida na \autoref{eq:funcaodehipotese}. Observe que ela tem apenas dois parâmetros. Na realidade uma hipótese pode ter vários parâmetros relacionados com os dados de entrada \textit{X}, se tiver \textit{n} dados de entrada, então haverá \textit{n+1} parâmetros. A forma geral da função de hipótese está mostrada na \autoref{eq:funcaodehipotesegeral}.

\begin{align}
h_{\theta}(x) = &\ \theta_0 + \theta_1 x \label{eq:funcaodehipotese} \\
h_{\theta}(x) = &\ \theta_0 + \theta_1 x_1 + \theta_2 x_2 + ... + \theta_n x_n \label{eq:funcaodehipotesegeral}
\end{align}

Uma maneira de simplificar a função de hipótese é trabalhar com a definição de multiplicação de matrizes. Então a função de hipótese pode ser representada de uma forma vetorizada, como mostrado na \autoref{eq:funcaodehipotesegeralvet}. Para maiores informações a respeito de matrizes e vetores, consultar o Anexo \ref{anexo:algebralinear}, que traz informações básicas de álgebra linear.

\begin{equation}
h_{\theta}(x) = \big[\theta_0\ \theta_1\ ...\ \theta_n\big] \times \begin{bmatrix} x_0 \\ x_1 \\ \vdots \\ x_n \end{bmatrix}  = \theta^TX \label{eq:funcaodehipotesegeralvet}
\end{equation}

Para que seja possível fazer operações de matrizes com $\theta$ e $X$, será setado $X_0^{(i)} = 1$ para todos os valores de $i$. Isso faz com que os vetores $\theta$ e $X^{(i)}$ combinem um com o outro elementarmente.

Uma função de hipótese tem o objetivo de mapear funções aleatórias dentro do intervalo de saída \textit{Y}. Portanto, nossa função de hipótese deve satisfazer a \autoref{eq:reglogicfuncaohip}.

\begin{equation}\label{eq:reglogicfuncaohip}
0 \leq h_{\theta}(x) \leq 1
\end{equation}

Para fazer com que uma entrada contínua fique nesse intervalo, é necessário utilizar uma função linear que faça esse mapeamento de modo linear, e para isso mudamos a forma da função de hipótese. A nova forma usa a função sigmoide, também conhecida como função logística.

\begin{align}
h_{\theta}(x) = g(\theta^TX) \nonumber \\
z = \theta^TX \nonumber \\
g(z) = \frac{1}{1 + e^{-z}} \label{eq:funcaosigmoide}
\end{align}

\begin{figure}[!htb]
  \caption{Função sigmoide}
  \label{fig:funcaosigmoide}
  \begin{center}
  \begin{tikzpicture}
  \begin{axis}[
  		width=.8\textwidth,
		scaled ticks=false,
		log ticks with fixed point,
		ymin=0,ymax=1,xmin=-10,xmax=10,domain=-10:10,
		log basis y = 10,
		xlabel=X,
      	ylabel=Y,
      	legend style={draw=none},
      	samples=200,
    ]
    \addplot[blue] { 1 / (1 + pow(e, -x))};
  \end{axis}
  \end{tikzpicture}
  \end{center}
\end{figure}

A função da \autoref{eq:funcaosigmoide} representada na fígura \autoref{fig:funcaosigmoide} mapeia qualquer número no intervalo [0, 1], tornando isso útil para transformar qualquer valor arbitrário em uma função mais ideal para problemas de classificação.

Para calcular a função de hipótese, podemos colocar o $\theta^TX$ na função logística. Isso nos dará a probabilidade de que a saída é 1.

\begin{equation}
h_{\theta}(x) = P(y=1 | X ; \theta) = 1 - P(y=0 | X ; \theta) \nonumber
\end{equation}

Ou seja, a probabilidade de nossa predição ser 1 é o oposto da probabilidade de ser 0. Sendo assim, a soma das probabilidades para \textit{y = 0} e \textit{y = 1} deve ser 1.

Para ter uma classificação discreta podemos traduzir a saída da função de hipótese de acordo com a \autoref{eq:decisionboundary}:
\begin{align} 
h_{\theta}(x) \geq 0.5 \Rightarrow y = 1 \nonumber \\
h_{\theta}(x) < 0.5 \Rightarrow y = 0 \label{eq:decisionboundary}
\end{align}

Então, se a entrada é $\theta^TX$, isso significa que:
\begin{equation}
h_{\theta}(x) = g(\theta^TX) \geq 0.5 \quad \text{ quando } \quad \theta^TX \geq 0 \nonumber
\end{equation}

A partir disso, podemos dizer que:
\begin{align}
\theta^TX \geq 0 \Rightarrow y = 1 \nonumber \\
\theta^TX < 0 \Rightarrow y = 0 \nonumber
\end{align}

O \textbf{limite de decisão} (ou barreira de decisão) é a linha que separa a área quando \textit{y = 0} e quando \textit{y = 1}. Isso é criado pela função de hipótese. Uma observação importante é que a função de hipótese não precisa ser linear, pode ser até mesmo um círculo ou ter qualquer forma para ajustar os dados, como mostrado na \autoref{fig:demclassificacao}. Isto é, uma função de hipótese pode ter várias \textit{features}. Novas \textit{features} podem ser criadas ao combinar as \textit{features} já existentes e modificando-as. Por exemplo, se houvesse dois dados de entrada $x_1$ e $x_2$, seria possível criar a função de hipótese:

\begin{equation}
\nonumber
h_{\theta}(x) = \theta_0 + \theta_1 x_1 + \theta_2 x_2 + \theta_3 x_1 x_2 + \theta_4 x_1^2 + \theta_5 x_2^2 + \theta_6 x_1^2 x_2^2 + \cdots
\end{equation}

Todavia, essa abordagem pode gerar problemas de desempenho. Algumas \textit{features} podem também acabar se tornando obsoletas e não ajudar em nada no resultado final, tornando seu cálculo inútil. Mas o principal problema dessa abordagem é o \textit{overfitting}, que faz com que a função de hipótese interpole os dados, esse problema será explicado na \autoref{subsec:regularizacao}.


\subsection{Função de custo}

Para medir a precisão da função de hipótese é necessário uma função que diga o quão precisa aquela hipótese é, tal função é denominada de função de custo. Com ela, é feita uma média de todos os resultados das hipóteses com a entrada \textit{X} comparada com o valor objetivo \textit{Y}. Ela pode ser expressa como na \autoref{eq:funcaodecusto}.

\begin{equation}
\label{eq:funcaodecusto}
J(\theta) = \frac{1}{m}\sum\limits_{i=1}^{m}Custo(h_{\theta}(x^{(i)}, y^{(i)}))
\end{equation}

Onde,


\begin{align}
 Custo(h_{\theta}(x^{(i)}, y^{(i)}) = \left\{
  \begin{array}{l l} 
    -log(h_{\theta}(x)) & \quad \text{se } y=1 \\
    -log(1 - h_{\theta}(x)) & \quad \text{se } y=0 \label{eq:funcaocusto}
  \end{array} \right.
\end{align}


A \autoref{eq:funcaocusto} captura a intuição de que se $h_\theta(x) = 0$, mas $y = 1$, então o algoritmo de aprendizado será penalizado por um custo muito alto. A \autoref{fig:logfunctions} demonstra os dois respectivos casos dessa equação.


\begin{figure}[!htb]
  \caption{Representação dos casos da função de custo}
  \label{fig:logfunctions}
  \begin{center}
  \begin{tikzpicture}

  % \draw[step=1cm,gray,very thin] (0,0) grid (11.3, 9.5);

  \begin{axis}[
  		width=.8\textwidth,
		scaled ticks=false,
		xlabel=$x$,
		log ticks with fixed point,
		ymin=0,ymax=2,xmin=0,xmax=1,domain=0:1,
		log basis y = 10,
      	legend style={draw=none},
      	samples=200,
    ]
    \addplot[blue] { - ln(x)/ln(10)};
    \addplot[orange] { - ln(1 - x)/ln(10)};
    \addlegendentry{$-log(h_{\theta}(x))$}
    \addlegendentry{$-log(1 - h_{\theta}(x))$}
  \end{axis}
  \end{tikzpicture}
  \end{center}
\end{figure}


O quanto mais a função de hipótese está longe de \textit{y}, maior é a saída da função de custo. Se a função de hipótese é igual a \textit{y}, então o custo é 0.

Podemos simplificar a \autoref{eq:funcaocusto} com dois casos condicionais em apenas um caso:

\begin{equation} 
\label{eq:funcaodecustosimplificada}
Custo(h_{\theta}(x), y) = -ylog(h_{\theta}(x)) - (1-y)log(1 - h_{\theta}(x))
\end{equation}

Nota-se que quando \textit{y} é igual a 1, o segundo termo será 0 e não afetará o resultado. E quando \textit{y} é igual a 0, o primeiro termo será 0 e não afetara o resultado. Aplicando a \autoref{eq:funcaodecustosimplificada} na função de custo da equação \autoref{eq:funcaodecusto}, podemos reescrê-la como a equação \autoref{eq:funcaodecustofinal} ou na versão vetorizada da \autoref{eq:funcaodecustovet}.

\begin{equation}
\label{eq:funcaodecustofinal}
J(\theta) = - \frac{1}{m}\sum\limits_{i=1}^{m}\Big( y^{(i)}log(h_{\theta}(x^{(i)})) + (1-y^{(i)})log(1 - h_{\theta}(x^{(i)})) \Big)
\end{equation}

\begin{equation}
J(\theta) = - \frac{1}{m}\Big( log(g(X\theta))^TY + log(1 - g(X\theta))^T(1 - Y) \Big) \label{eq:funcaodecustovet}
\end{equation}

O objetivo da regressão logística é minimizar a função de custo em relação aos parâmetros $\theta$s. Usando dois parâmetros é possível visualizar uma função de custo através do número de iterações, isso pode ser observado no exemplo da \autoref{fig:funcaodecustosurf} e da \autoref{fig:funcaodecustocontorno}. 


\begin{figure}
  \caption{Função de custo - $J(\theta_0, \theta_1)$}
  \begin{subfigure}[htb]{0.5\textwidth} \label{fig:funcaodecustosurf}
    \includegraphics[width=\textwidth]{img/funcaodecustosurf} 
    \legend{(a) Gráfico de superfície} 
  \end{subfigure} 
  %
  \begin{subfigure}[htb]{0.5\textwidth} \label{fig:funcaodecustocontorno}
    \includegraphics[width=\textwidth]{img/funcaodecustocontorno} 
    \legend{(b) Gráfico de contorno}
  \end{subfigure} 

  \legend{Fonte: \citeonline{machinelearningcoursera}}
\end{figure}


\subsection{Minimização da função de custo}

Para essa tarefa é necessário a aplicação de um algoritmo que pega a função de custo e tente minimizá-la, e por fim retorne os valores dos parâmetros $ \theta $s aprendidos. Com isso, estaremos melhorando nossa função de hipótese. 

Um dos algoritmos mais utilizados para essa tarefa é o \textbf{Gradiente Descendente} \cite{michalski2013machine}, seu funcionamento baseia-se em seguir a derivida da função de custo em relação aos parâmetros $\theta$s alternadamente, com isso a encosta da tangente dará a direção para seguir adiante. Ademais, é aplicada uma taxa de aprendizagem $ \alpha $ a cada iteração, para tentar controlar a convergência.

Seu funcionamento é descrito pelo algoritmo \ref{eq:gradientedesc}.

\textit{repita até convergir \{}
\begin{equation}
\label{eq:gradientedesc}
\quad \theta_j := \theta_j = \alpha \frac{\partial}{\partial\theta_j} J(\theta)
\end{equation}
\textit{\quad\quad\quad \}}

Ao trabalhar sobre a derivada parcial da função de custo, podemos chegar na \autoref{eq:gradientefinal} e adiante na versão vetorizada na \autoref{eq:gradientefinalvet}. A explicação de como trabalhar sobre a derivada pode ser encontrado no \autoref{app:derivadasgraddesc}.

\begin{equation}
\quad \theta_j := \theta_j = \alpha \sum\limits_{i=1}^{m}\Big(h_{\theta}(x^{(i)}) - y^{(i)} \Big) x_j^{(i)} \label{eq:gradientefinal}
\end{equation}

\begin{equation}
\quad \theta := \theta - \frac{\alpha}{m}X^T(g(X\theta) - Y) \label{eq:gradientefinalvet}
\end{equation}

Na \autoref{fig:funcgraddesc} é possível visualizar esse funcionamento sobre os parâmetros. Observe que nesse caso o algoritmo consegue convergir para o mínimo global, porém em alguns casos (dependendo de nossa taxa de aprendizagem $ \alpha $) pode-se convergir para um mínimo local como mostrado na \autoref{fig:funcgraddescnot}. Basicamente se $\alpha$ for um valor muito alto, os passos para o mínimal ótimo serão grandes e portanto o risco de divergência é maior, caso seja muito baixo, os passos para o mínimal ótimo serão pequenos e portanto vai demorar muito para convergir. Em \cite{machinelearningcoursera}, é dito para testar manualmente esse valor, começando com 0,001 e subindo multiplicando por 10 esse valor até atingir uma divergência no resultado. Sendo assim possível analisar o melhor valor da taxa de aprendizagem e selecioná-la para o treinamento definitivo.

\begin{figure}
  \caption{Funcionamento do Gradiente Descendente}
  \begin{subfigure}[htb]{0.5\textwidth} \label{fig:funcgraddesc}
    \includegraphics[width=\textwidth]{img/funcgraddesc1}
    \legend{(a) Convergindo para uma mínimo global} 
  \end{subfigure}
  %
  \begin{subfigure}[htb]{0.5\textwidth} \label{fig:funcgraddescnot}
    \includegraphics[width=\textwidth]{img/funcgraddesc2}
    \legend{(b) Convergindo para uma mínimo local}
  \end{subfigure}

  \legend{Fonte: \citeonline{machinelearningcoursera}}
\end{figure}

O Gradiente Descendente é apenas um dos vários algoritmos que existem para minimizar a função de custo. De acordo com \cite{machinelearningcoursera}, há alternativas mais sofisticadas como o Gradiente Conjugado, BFGS e L-BFGS, onde além de serem mais rápidos que o Gradiente Descendente, eles não precisam selecionar manualmente o valor de $\alpha$. Mas, também é sugerido que não devemos tentar codificar esses algoritmos, visto que são mais complexos e requerem um bom conhecimento de cálculo numérico.


\subsection{Classificação multiclasse}

O \ac{pos} Tagging é um problema de classificação multiclasse, onde deve-se etiquetar uma palavra em uma de várias categorias gramaticais possíveis. É possível fazer isso ao expandir nossa definição para que a saída seja $y = \{0, 1, ..., n\}$. Nesse caso, é dividido o problema em \textit{n + 1} problemas de classificação binária e em cada um será feito a predizagem da probabilidade de que $y$ é membro de uma dessas classes.
\begin{align}
h_{\theta}^{(0)}(X) =&  P(y=0 | X ; \theta) \nonumber \\
h_{\theta}^{(1)}(X) =&  P(y=1 | X ; \theta) \nonumber \\
\vdots & \nonumber \\
h_{\theta}^{(n)}(X) =&  P(y=n | X ; \theta) \nonumber
\end{align}

E então escolhe-se a classe com o valor de hipótese mais alto.
\begin{equation}
prediction = max_i(h_{\theta}^{(i)}(X)) \nonumber
\end{equation}


\subsection{Regularização}\label{subsec:regularizacao}

Como já mencionado, regularização é um conceito importante designado para resolver o problema de \textit{overfitting}.

Quando se trabalha com abordagens de aprendizagem supervisionada, tem dois problemas que podem ocorrer dependendo das \textit{features} escolhidas. O \textbf{\textit{underfitting}} ocorre quando a forma da função de hipótese mapeia mal à tendência dos dados. Isso é causado por uma função que é muito simples ou que usa pouquíssimas \textit{features}. Em contrapartida, \textbf{\textit{overfitting}} é causado por uma função de hipótese que encaixa os dados avaliados mas não generaliza bem para classificar novos dados. É usualmente causado por uma função complexa que cria muitas curvas e ângulos desnecessários não relacionados aos dados.

\begin{figure}
  
  \caption{Exemplo de \textit{underfitting} e \textit{overfitting}} \label{fig:exemplounderover}
  
  \begin{subfigure}[htb]{0.5\textwidth}
    \includegraphics[width=\textwidth]{img/underfittingex}
    \legend{(a) \textit{underfitting}} 
  \end{subfigure}
  %
  \begin{subfigure}[htb]{0.5\textwidth}
    \includegraphics[width=\textwidth]{img/overfittingex}
    \legend{(b) \textit{overfitting}}
  \end{subfigure}

  \legend{Fonte: \citeonline{machinelearningcoursera}}
\end{figure}

A classificação ideal para o conjunto de dados mostrados na \autoref{fig:exemplounderover} é o exemplo mostrado na \autoref{fig:demclassificacao}.

Segundo \cite{machinelearningcoursera}, há duas opções principais para resolver o problema de \textit{overfitting}:

\begin{alineas}
	\item Reduzir o número de \textit{features}:
		\begin{alineas}
			\item Manualmente selecionar quais \textit{features} usar;
			\item Usar um algoritmo de seleção de modelo.
		\end{alineas}
	\item Regularização:
		\begin{alineas}
			\item Manter todos as \textit{features}, mas reduzir os parâmetros $\theta_j$.
		\end{alineas}
\end{alineas}

Em geral, regularização funciona bem quando há bastante features levemente úteis.


\section{Córpus e seu conjunto de classes gramaticais}

Córpus são uma coleção de textos colocados como um só, eles são os exemplos de entrada para nosso treinamento. A qualidade e o tamanho desses córpus são importantes para que o etiquetador possa generalizar sentenças ainda não vistas. Eles contém também um conjunto de classes gramaticais associadas a cada palavra.

Esses conjuntos podem se diferenciar na sua granularidade, como por exemplo, podem ter diferentes classes gramaticais para nomes no plural e no singular, ou agrupar eles em uma única classe \cite{fonseca2015evaluating}. No inglês, há vários conjunto de classes gramaticais de qualidade que são amplamento utilizados, são o Penn Treebank tagset \cite{penntreebank}, CLAWS5 e CLAWS7.

Já no português, os córpus estão evoluindo com o tempo, embora alguns erros são encontrados neles \cite{fonseca2013mac}, eles ainda são a melhor opção devido a seu tamanho e qualidade, os principais e mais utilizados para essa tarefa são o Mac-Morpho \cite{aluisio2003account} com cerca de um milhão de palavras, que retrata artigos publicados na Folha de São Paulo em 1994. O Tycho Brahe \cite{temponi2004corpus} que também tem cerca de um milhão de palavras e retrata assuntos históricos de 66 textos diferentes. Temos também o Bosque \cite{afonso2002floresta}, que contém cerca de 185 mil palavras. Além desses, \cite{fonseca2015evaluating} apresenta uma versão revisada do Mac-Morpho, com classes gramaticais novas e junção de outras. 

Infelizmente esses córpus não podem ser combinados em um só, já que eles se diferenciam no conjunto de classes gramaticais e também no seu uso associado. Uma possível alternativa para essa combinação, seria o uso de uma aprendizagem não supervisionada, aplicando técnicas de clusterização.

A aprendizagem baseada em córpus tem se mostrado uma estratégia atrativa, já que pode ser usado recursos criados com melhores performance [X, Y, Z]. Devido a isso, nesse trabalho vamos utilizar três córpus: o Mac-Morpho original; Mac-Morpho revisado e o Tycho Brahe. O conjunto de etiquetas para esses córpus podem ser encontrados, respectivamente, em \cite{aluisio2003account}, \cite{fonseca2015evaluating} e \cite{temponi2004corpus}.



\section{Representação das palavras}\label{sec:representacaodaspalavras}

Palavras \footnote{Uma palavra pode ser qualquer conjunto de caracteres, inclusive pontuações, números, etc.} podem ser representadas de várias maneiras em um modelo de aprendizagem, podendo ser até mesmo feito o uso real da palavra como um conjunto de caracteres.

No entanto, a melhor abordagem e a mais indicada atualmente é a utilização de \textit{word embeddings}, elas são representação de palavras como vetores reais valorados em um espaço multidimensional \cite{turian2010word}. Elas podem ser geradas de maneiras diferentes dependendo da técnica utilizada, clássicas abordagens baseiam-se na frequência e co-ocorrência das palavras, até mesmo via modelos de redes neurais \cite{dos2014training}. Um dos processos de criação é mostrado na \autoref{fig:criacaowordemb}.

\begin{figure}[htb]
  \caption{Exemplo de criação de \textit{word embeddings}} \label{fig:criacaowordemb}
  \begin{center}
      \includegraphics[scale=0.3]{img/criacaowordemb}
  \end{center}
\end{figure}


Ou seja, dada uma palavra \textit{word}, temos a transformação \textit{W}:
\begin{equation}
W:word \to \mathbb{R}^n
\end{equation}

Em ordem de prever esses valores com precisão, a rede precisa aprender bons parâmetros para \textit{W}.

A grande vantagem em se utilizar \textit{word embeddings} é o fato dessa técnica conseguir capturar informações sintáticas e semânticas das palavras. Isso pode ser visualizado através do t-SNE \cite{van2008visualizing}, uma técnica sofisticada para visualizar dados em altas dimensões.

\begin{figure}[htb]
  \caption{t-SNE: Visualização para \textit{word embeddings}}\label{fig:wordtsne}
  \begin{center}
      \includegraphics[scale=0.25]{img/Turian-WordTSNE}
  \end{center}
  \legend{Fonte: \citeonline{turian2010word}}
\end{figure}

Na \autoref{fig:wordtsne} podemos visualizar um tipo de mapeamento entre os sentidos intuitivos das palavras, onde na esquerda estão palavras referentes a números e na direita palavras referentes a profissões. Ou seja, palavras similares estão pertos umas das outras.

\begin{figure}[htb]
  \caption{Exemplo de palavras similares}\label{fig:palavrassimilares}
  \begin{center}
      \includegraphics[scale=0.25]{img/Colbert-WordTable2}
  \end{center}
  \legend{Fonte: \citeonline{collobert2011natural}}
\end{figure}

Na \autoref{fig:palavrassimilares} temos mais alguns exemplos desse conceito, com isso podemos realizar tarefas semânticas mais facilmente, como o exemplo \ref{eq:exemploobjetivo}, que é o que esperamos obter.

Para mais informações sobre \textit{word embeddings} consultar [X] e [Y].



\section{Redes neurais}

O que escrever aqui? 

- Conceitos basicos de redes neurais



\section{Aprendizagem profunda}

- Redes neurais profundas e seus algoritmos