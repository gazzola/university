%==============================================================================
\chapter{Trabalhos relacionados}\label{trabalhosrelacionados}
%==============================================================================

Vários métodos já foram propostos para resolver esse mesmo problema em português brasileiro, apesar de nenhum deles ter um aproveitamento de 100\%, vários conseguiram ótimos resultados e utilizaram variadas técnicas para isso.

É apresentado em \cite{kepler2005etiquetador} um etiquetador morfo-sintático baseado em cadeias de Markov. É realizado testes com dois etiquetadores diferentes, um baseado em Cadeias de Markov Ocultas (HMM, do inglês \textit{Hidden Markov Models}), e outro baseado em Cadeias de Markov de Tamanho variável (VLMC, do inglês \textit{Variable Length Markov Chains}). A representação das palavras é feita de forma simples, pois a etiquetagem baseia-se em modelos probabilísticos, onde a etiqueta de uma palavra depende da própria palavra e de etiquetas anteriores. Ele é testado sobre o \textit{córpus} Tycho Brahe, e apresenta uma precisão de 95,51\% com o etiquetador VLMC, essa precisão é alcançada com um tempo de aprendizagem + etiquetagem de 157 segundos. 

Em \cite{dos2014training} é apresentado um etiquetador que aprende automaticamente as features a serem usadas através de uma rede neural profunda que emprega uma camada evolutiva capaz de aprender \textit{embeddings} em nível de caractere e em nível de palavra. Essa rede neural profunda é conhecida como CharWNN e foi proposta originalmente por \citeonline{collobert2011natural}. Além disso, é usado um modelo em janela utilizado em \cite{collobert2011natural} para atribuir classes gramaticais para cada palavra em uma sentença. Essa estratégia assume que a classe de uma palavra depende geralmente das palavras vizinhas. No fim é utilizado o algoritmo de Viterbi \cite{viterbi1967error} para prever qual a sequência de classes gramaticais é a mais provável para aquela sentença, para então ser treinada em um modelo de rede neural com algumas \textit{features} que obtém informações dos formatos da palavra. Esse trabalho usa três diferentes \textit{córpus} para o treinamento: o Mac-Morpho original; o Mac-Morpho revisado em \cite{fonseca2013mac}; e o Tycho Brahe. Eles avaliam seu modelo sobre palavras fora do vocabulário e sobre palavras presente no vocabulário. Com o Mac-Morpho foi obtido o melhor desempenho do trabalho, uma acurácia de 97,47\% sobre palavras \ac{ddv}. Nesse trabalho não é mostrado estatísticas de tempo de treinamento e etiquetagem.

O mais recente etiquetador para o português brasileiro é mostrado em \cite{fonseca2015evaluating}, onde é utilizado diferentes técnicas de representação das palavras: vetores gerados de forma aleatória, \ac{nlm}, \ac{hal}, \ac{sg}. É feita então uma comparação entre elas. Nele é implementado um modelo de rede neural profunda idealizado em \cite{collobert2008unified}, que se baseia em uma rede neural com simples com múltiplas camadas que recebe as \textit{word embeggins} como entrada e aprende a sua classe gramatical. Para isso, eles realizam o treinamento utilizando o Tycho Brahe, a versão original do Mac-Morpho (versão 1) e a revisada pelos mesmos autores em um trabalho anterior \cite{fonseca2013mac} (versão 2), e também sobre mais uma versão do Mac-Morpho revisado (versão 3) por eles nesse mesmo trabalho. Atualmente, \citeonline{fonseca2015evaluating} dizem ter alcançado o estado-da-arte do \ac{pos} Tagging para o português brasileiro, com uma acurácia de 97,57\% sobre o Mac-Morpho original e no escopo de palavras \ac{ddv}. Esse trabalho não apresenta estatísticas de tempo de treinamento e etiquetagem.

A \autoref{tab:comparacaotrabsrel} sumarizada as técnicas e resultados encontrados pelos trabalhos relacionados que tentam resolver o mesmo problema que este trabalho.

\begin{table}[!htb]
\footnotesize
\centering
\caption{Comparativo entre técnicas e resultados encontrados na literatura para o problema de \ac{pos} Tagging.}
\label{tab:comparacaotrabsrel}
\begin{tabular}{m{2cm}m{3cm}m{3cm}m{4cm}m{2cm}}
  \toprule
  \textbf{Autores} & \textbf{Modelo}  & \textbf{Representação das palavras}  & \textbf{Córpus} & \textbf{Acurácia} \\
  \midrule
  \citeonline{kepler2005etiquetador} & VLMM & Sequência de caracteres & Tycho Brahe & 95,51\% \\
  \citeonline{dos2014training} & Redes neurais profundas  & Representação vetorial (CharWNN) & Tycho Brahe; Mac-Morpho v1, v2 & 97,47\% \\
  \citeonline{fonseca2015evaluating} & Redes neurais & Representação vetorial (\ac{nlm}, \ac{hal}, \ac{sg}) & Tycho Brahe; Mac-Morpho v1, v2, v3; & 97,57\% \\
  Este trabalho & Redes neurais profundas & Representação vetorial (\ac{nlm}, \ac{sg}, \ac{glove}) & Tycho Brahe; Mac-Morpho v1, v3 & - \\
  \bottomrule
\end{tabular}
\end{table}


% nome trab - modelo - representacao  - corpus - acuracia - tempo