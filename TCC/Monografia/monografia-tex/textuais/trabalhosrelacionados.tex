%==============================================================================
\chapter{Trabalhos relacionados}\label{trabalhosrelacionados}
%==============================================================================

Vários métodos já foram propostos para resolver o problema de \ac{pos} Tagging para o português brasileiro, apesar de nenhum deles ter uma acurácia de 100\%, vários conseguiram ótimos resultados e utilizaram variadas técnicas para isso.

Em \cite{kepler2005etiquetador} é apresentado um etiquetador morfossintático baseado em cadeias de Markov. São realizados testes com dois etiquetadores diferentes, um baseado em Cadeias de Markov Ocultas (HMM, do inglês \textit{Hidden Markov Models}), e outro baseado em Cadeias de Markov de Tamanho variável (VLMC, do inglês \textit{Variable Length Markov Chains}). A representação das palavras é feita de forma simples, pois a etiquetagem baseia-se em modelos probabilísticos, em que etiqueta de uma palavra depende da própria palavra e de etiquetas anteriores. Ele é testado sobre o \textit{córpus} Tycho Brahe, e apresenta uma acurácia de 95,51\% com o etiquetador VLMC, essa acurácia é alcançada com um tempo de aprendizagem + etiquetagem de 157 segundos.  O VLMC é usando novamente em \cite{kepler2010variable} e consegue-se uma acurácia de 96.29\%.

% http://www.ime.usp.br/~kepler/vlmmtagger/

Em \cite{dos2014training} é apresentado um etiquetador que aprende automaticamente as features a serem usadas através de uma rede neural profunda, que emprega uma camada evolutiva capaz de aprender \textit{embeddings} em nível de caractere e em nível de palavra. Essa rede neural profunda é conhecida como CharWNN e foi proposta originalmente por \citeonline{collobert2011natural}. Além disso, é usado um modelo em janela utilizado em \cite{collobert2011natural} para atribuir classes gramaticais para cada palavra em uma sentença. Essa estratégia assume que a classe de uma palavra depende geralmente das palavras vizinhas. No fim é utilizado o algoritmo de Viterbi \cite{viterbi1967error} para prever qual a sequência de classes gramaticais é a mais provável para aquela sentença. Esse trabalho usa três diferentes \textit{córpus} para o treinamento: o Mac-Morpho original; o Mac-Morpho (versão 2) revisado em \cite{fonseca2013mac}; e o Tycho Brahe. Eles avaliam seu modelo sobre palavras fora do vocabulário e sobre palavras presentes no vocabulário. Com o Mac-Morpho foi obtido o melhor desempenho do trabalho, uma acurácia de 97,47\%. Nesse trabalho não é mostrado estatísticas de tempo de treinamento e etiquetagem.

O mais recente etiquetador para o português brasileiro é mostrado em \cite{fonseca2015evaluating}, onde diferentes técnicas de representação das palavras são utilizadas: vetores gerados de forma aleatória, \ac{nlm}, \ac{hal}, \ac{sg}. É feita então uma comparação entre elas. Nele é implementado um modelo de rede neural idealizado em \cite{collobert2008unified}, que se baseia em uma rede neural simples com múltiplas camadas, que recebe as \textit{word embeddings} como entrada e aprende a sua classe gramatical. Para isso, eles realizam o treinamento utilizando o Tycho Brahe, a versão original do Mac-Morpho (versão 1), a revisada pelos mesmos autores em um trabalho anterior \cite{fonseca2013mac} (versão 2), e também sobre mais uma versão do Mac-Morpho (versão 3) revisado por eles nesse mesmo trabalho. Atualmente, \citeonline{fonseca2015evaluating} dizem ter alcançado o estado da arte do \ac{pos} Tagging para o português brasileiro, com uma acurácia de 97,57\% sobre o Mac-Morpho original utilizando \ac{nlm} como representação das palavras. Esse trabalho não apresenta estatísticas de tempo de treinamento e etiquetagem.

A \autoref{tab:comparacaotrabsrel} sumarizada as técnicas encontradas nos trabalhos relacionados. Já a \autoref{tab:comparacaotrabsrelac} mostra os melhores resultados para cada \textit{córpus}.

\begin{table}[!htb]
\footnotesize
\centering
\caption{Comparativo das técnicas encontradas na literatura para POS Tagging}
\label{tab:comparacaotrabsrel}
\begin{tabular}{m{3cm}m{2.5cm}m{4.1cm}m{5cm}}
  \toprule
  \textbf{Autores} & \textbf{Modelo}  & \textbf{Representação das palavras}  & \textbf{Córpus} \\
  \midrule
  \citeonline{kepler2005etiquetador} & VLMM & Sequência de caracteres & Tycho Brahe \\
  \citeonline{dos2014training} & Redes neurais profundas  & Vetores (CharWNN) & Tycho Brahe; Mac-Morpho (versões 1, 2) \\
  \citeonline{fonseca2015evaluating} & Redes neurais & Vetores (\ac{nlm}, \ac{hal}, \ac{sg}) & Tycho Brahe; Mac-Morpho (versões 1, 2, 3) \\
  Este trabalho & Redes neurais recursivas & Vetores (\ac{nlm}, \ac{sg}, \ac{glove}) & Tycho Brahe; Mac-Morpho (versões 1, 3) \\
  \bottomrule
\end{tabular}
\end{table}

\begin{table}[!htb]
\footnotesize
\centering
\caption{Comparativo dos melhores resultados encontrados na literatura para POS Tagging}
\label{tab:comparacaotrabsrelac}
\begin{tabular}{llP{3cm}P{3cm}}
  \toprule
  \textbf{Autores} & \textbf{Córpus} & \textbf{Acurácia (Todas Palavras)} & \textbf{Acurácia (\ac{fdv})} \\
  \midrule
  \centering
  \citeonline{kepler2005etiquetador} & Tycho Brahe & 95,51\% & 69,53\% \\
  \citeonline{kepler2010variable}  & Tycho Brahe & 96,29\% & 71,60\% \\
  \citeonline{dos2014training} 		 & Tycho Brahe & 97,17\% & 86,63\% \\
  \citeonline{dos2014training} 		 & Mac-Morpho versão 1 & 97,47\% & 89,74\% \\
  \citeonline{dos2014training} 		 & Mac-Morpho versão 2 & 97,31\% & 92,61\% \\
  \citeonline{fonseca2015evaluating} \tablefootnote{\label{notenlm} Usando \ac{nlm} como representação das palavras.} & Tycho Brahe & 96,91\% & 84,14\% \\
  \citeonline{fonseca2015evaluating} \footnoteref{notenlm} & Mac-Morpho versão 1 & 97,57\% & 93,38\% \\
  \citeonline{fonseca2015evaluating} \footnoteref{notenlm} & Mac-Morpho versão 2 & 97,48\% & 94,34\% \\
  \citeonline{fonseca2015evaluating} \footnoteref{notenlm} & Mac-Morpho versão 3 & 97,33\% & 93,66\% \\
  \bottomrule
\end{tabular}
\end{table}


% nome trab - modelo - representacao  - corpus - acuracia - tempo