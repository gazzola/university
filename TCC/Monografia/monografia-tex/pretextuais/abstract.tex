\begin{resumo}[Abstract]
 
Part-of-speech Tagging consists in classify a given word, that belongs to a collections of texts, with particular part of speech tag. Part-of-speech Tagging can be used as pre-processing of many applications, so, in Natural Language Processing we are always searching for improvement methods. We study different methods to generate words representations (word embeddings). We propose two deep learning models: a recursive neural network model and a bidirectional recurrent neural network model. The recursive neural model is guided, where easy words to predict are classified first. The training was made with three different corpora for Brazilian Portuguese. For each model, we evaluate the accuracy over those corpora using three types of word embeddings, and then we analysed the mistakes made by them. Furthermore, we compare our result with related works, and we found that our bidirectional recurrent model reached the second top accuracy over original Mac-Morpho for out-of-vocabulary words. Our experiments show that the bidirectional recurrent model is more efficient than recursive model in terms of accuracy and training time. This work contributes with a definition and an implementation of two taggers that were made available to the community and can be used freely.

 \vspace{\onelineskip}
 
 \noindent 
 \textbf{Key-words}: Machine Learning. Deep Learning. Natural Language Processing. Part-of-speech Tagging. Recursive Neural Networks. Bidirectional Recurrent Neural Networks. Word Embeddings.
\end{resumo}
